buildscript {
  repositories {
    jcenter()
    mavenCentral()
    maven { url 'http://repo.spring.io/plugins-release' }
    maven { url "http://clojars.org/repo" }
  }
  dependencies {
    classpath 'com.netflix.nebula:gradle-extra-configurations-plugin:2.2.1'
    classpath 'org.apache.maven:maven-artifact:2.2.1' // 3.x won't work
    classpath 'org.apache.avro:avro-compiler:1.7.7'
    classpath 'org.apache.avro:avro-tools:1.7.7'
    classpath 'org.clojars.miguno:avro-gradle-plugin:1.7.7.2'
    classpath 'org.hidetake:gradle-ssh-plugin:2.7.0'
  }
}

//applying different property files, which name is passed through gradle -D property.
Properties props = new Properties()
props.load(new FileInputStream("$project.rootDir/environment/sandbox.properties"))
//props.load(new FileInputStream("$project.rootDir/environment/${System.properties['host_properties']}.properties"))

props.each { prop ->
  project.ext.set(prop.key, prop.value)
}

//apply customerID and ce_supplierId to property file, checking whether they exist and rewrite values
def oozie_property_file = new File('src/main/resources/sandbox_oozie.properties');
String contents = new File('src/main/resources/sandbox_oozie.properties').getText( 'UTF-8' );
def customer_Id = '\ncustomerID=' + "${System.properties['customerID']}";
def supplier_Id = '\nce_supplierId=' + "${System.properties['ce_supplierId']}";
if(contents.contains("customerID") || contents.contains("ce_supplierId")) {
  contents = contents.replaceAll('\ncustomerID=(.*)', customer_Id )
  contents = contents.replaceAll('\nce_supplierId=(.*)', supplier_Id )
  oozie_property_file.write(contents, 'UTF-8')
} else {
  oozie_property_file.append(customer_Id);
  oozie_property_file.append(supplier_Id);
}




apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'eclipse'
apply plugin: 'provided-base'
apply plugin: 'avro-gradle-plugin'
apply plugin: 'checkstyle'
apply plugin: 'findbugs'
apply plugin: 'pmd'
apply plugin: 'org.hidetake.ssh'

archivesBaseName = 'facility'

ext.cascadingVersion = '3.0.0'
ext.hadoopVersion = '2.7.3'
sourceCompatibility = 1.7
targetCompatibility = 1.7
checkstyle.toolVersion = '6.18'
findbugs.toolVersion = '3.0.1'
pmd.toolVersion = '5.5.2'

compileAvro {
  source = 'src/main/avro'
  destinationDir = file("src/main/java")
  stringType = 'String'
}

repositories {
  mavenLocal()
  mavenCentral()
  maven { url 'http://conjars.org/repo/' }
}

dependencies {
  compileAvro
  compile( group: 'cascading', name: 'cascading-core', version: cascadingVersion )
  compile( group: 'cascading', name: 'cascading-local', version: cascadingVersion )
  compile( group: 'cascading', name: 'cascading-hadoop2-mr1', version: cascadingVersion )
  compile( group: 'cascading', name: 'cascading-hadoop', version: cascadingVersion )
  compile( group: 'org.apache.avro', name: 'avro', version: '1.7.7')
  compile( group: 'org.apache.avro', name: 'avro-tools', version: '1.7.7')
  compile( group: 'org.apache.oozie', name: 'oozie-client', version: '4.1.0')
  compile('org.mongodb:mongo-java-driver:3.2.2')



  provided( group: 'org.apache.hadoop', name: 'hadoop-common', version: hadoopVersion )
          {exclude module: 'avro'}
  provided( group: 'org.apache.hadoop', name: 'hadoop-client', version: hadoopVersion )
          {exclude module: 'avro'}
  provided( group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-core', version: hadoopVersion )
          {exclude module: 'avro'}
}

jar {
  description = "Assembles a Hadoop ready jar file"
/*  doFirst {
    into( 'lib' ) {
      from { configurations.compile.minus( [configurations.provided] ) }
    }
  }*/
  manifest {
    attributes( "Main-Class": "com/nixsolutions/hadoop/facilityavro/Main" )
  }
}
//copy dependecies jar files to build/libs
task install(type: Copy) {
  dependsOn build
  from configurations.runtime
  into "${project.projectDir}/build/libs"
}

//checkstyle
tasks.withType(Checkstyle) {
  reports {
    source 'src'
    html.enabled false
    xml.enabled true
    xml.destination rootProject.file("build/reports/checkstyle/checkstyle-result.xml")
    ignoreFailures = true
  }
}

//findbugs
tasks.withType(FindBugs) {
  reports {
    html.enabled false
    xml.enabled true
    xml.destination rootProject.file("build/reports/findbugs/findbugs.xml")
    effort = "max"
    reportLevel = "high"
    ignoreFailures = true
  }
}

//pmd
tasks.withType(Pmd) {
  reports {
    ignoreFailures = true
    html.enabled false
    xml.enabled true
    xml.destination rootProject.file("build/reports/pmd/pmd.xml")
    ruleSets = [
            'java-basic',
            'java-braces',
            'java-clone',
            'java-codesize',
            'java-comments',
            'java-controversial',
            'java-coupling',
            'java-design',
            'java-empty',
            'java-finalizers',
            'java-imports',
            'java-j2ee',
            'java-javabeans',
            'java-junit',
            'java-logging-jakarta-commons',
            'java-logging-java',
            'java-migrating',
            'java-naming',
            'java-optimizations',
            'java-strictexception',
            'java-strings',
            'java-sunsecure',
            'java-typeresolution',
            'java-unnecessary',
            'java-unusedcode'
    ]
  }
}

//Setting up SSH plugin to connect with remote server
remotes {
  sandbox {
    role 'masterNode'
    host = project.host
    user = project.username
    password = project.password
  }
}
//allow all host to be connected to
ssh.settings {
  knownHosts = allowAnyHosts
}
//task for executing remote commands
task deploymenttohost(dependsOn: install) {

  doLast{
    ssh.run {
      session(remotes.sandbox) {
        //execute 'oozie jobs -oozie http://' + project.host + ':11000/oozie -kill -filter name=HadoopTestFacilityAvro -jobtype coordinator';
        execute 'rm -rf build;'
        execute 'mkdir build; cd build; mkdir config; mkdir libs'
        put from: file('build/libs/**.*'), into: 'build/libs';
        put from: file('src/main/resources/**.*'), into: 'build/config';
        put from: file('environment/**.*'), into: 'build/config';
        execute 'hadoop fs -rm -r -f /app';
        execute 'hdfs dfs -mkdir /app';
        execute 'hdfs dfs -mkdir /app/config';
        execute 'hdfs dfs -mkdir /app/jar';
        execute 'hdfs dfs -put build/libs/**.jar /app/jar/';
        execute 'hdfs dfs -put build/config/**.* /app/config/';

        execute 'oozie job -oozie http://' + project.host + ':11000/oozie -auth SIMPLE -config build/config/sandbox_oozie.properties -run'
        execute 'rm -rf build;'
      }
    }
  }
}